{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> GroupRec </center>\n",
    "\n",
    "__Team__: Bhavik Ameta, Parul Priya, Shobhit Jain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Problem Statement: \n",
    "In the past, a lot of effort has been put towards finding the recommendations for a given user in different fields. But many a times it is seen that people like to do certain activities in groups like, camping or watching movies. In such a case there is a need for a recommender which takes care of the interests of each individual of the group and suggests items which are likely to be enjoyed by the entire group. So hereby we present the idea of a Group Recommendation System for movies. \n",
    "\n",
    "We are proposing to implement the idea using Matrix Factorization (MF) based Collaborative Filtering. The main idea of MF models is to factorize the original rating matrix into two or more matrices in order to represent the user-item interactions. We will be using various approaches to calculate these factors for groups using those of individual users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Related Work:\n",
    "The most popular method to compute recommendations for a group of users is KNN based CF.The data sparsity issues related to KNN can be tackled by using a support vector machine learning model that computes similarities between items. Another approach defines the set of neighbors of the group as the intersection of the sets of neighbors of each user of the group.\n",
    "\n",
    "Although for single user recommendations, MF based CF has been extensively studied, its implementation for group recommendation has not been carried out in depth. One such approach has been proposed in an earlier paper which modifies the MF model to include a wide variety of sociological factors such as cohesion, social similarity and social centrality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset :\n",
    "We have used MovieLens 100k data set for our project.\n",
    "\n",
    "https://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach:\n",
    "The system takes a group size as input, generates random groups and produces movie recommendations based on group members' biases. \n",
    "The following approaches are being used for the same : \n",
    "<ul>\n",
    "<li>AF (After factorization) : Here we first factorize user x item matrix and then calculate factors for users. We then aggregate these factors to approximate the factors for the groups of users. Using these group factors, we can calculate group ratings for items based on these factors and biases.</li>\n",
    "<li>BF (Before factorization ) : In BF (before factorization) approach, we aggregate ratings of the users before factorization of ratings matrix and calculate group rating . We can assume group as a virtual user from this step. Now we derive factors and biases for the groups. The idea of ridge regression has been used for this approach.</li>\n",
    "<li>WBF (Weighted BF) : The weighted BF approach is similar to BF method except that here each item is associated with a weight depending upon the number of users who have watched it and how similar are the corresponding ratings. Hence the stochastic gradient minimization function will be different.</li>\n",
    "</ul>\n",
    "\n",
    "Also the different sizes of groups being considered are :\n",
    "<ul>\n",
    "<li>Small (2-4 users),</li>\n",
    "<li>medium (5-8 users) and  </li>\n",
    "<li>large groups (9-12 users)</li>\n",
    "</ul>\n",
    "![title](./res/flowchart.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE: \n",
    "Here we present the code for the project. We have first presented all the major class definitions in the project, followed by the main script code that actually runs and gives the output statistics and graphs.\n",
    "These are the main classes:\n",
    "<li> Group: The methods and parameters for group of users </li>\n",
    "<li> GroupRec: The main class with methods for AF, BF and WBF </li>\n",
    "<li> Aggregator: utility functions for different types of aggregation (average, weighted average etc.) </li>\n",
    "\n",
    "<h4>Group Class :</h4>\n",
    "The class 'Group' is responsible for generating random groups of different sizes : small, medium and large and performing evaluations of different methods AF, BF and WBF used for recommendation for these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ConfigParser\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, members, candidate_items, ratings):\n",
    "        # member ids\n",
    "        self.members = sorted(members)\n",
    "        \n",
    "        # List of items that can be recommended.\n",
    "        # These should not have been watched by any member of group.\n",
    "        self.candidate_items = candidate_items\n",
    "\n",
    "        self.actual_recos = []\n",
    "        self.false_positive = []\n",
    "        \n",
    "        self.ratings_per_member = [np.size(ratings[member].nonzero()) for member in self.members]\n",
    "        \n",
    "        # AF\n",
    "        self.grp_factors_af = []\n",
    "        self.bias_af = 0\n",
    "        self.precision_af = 0\n",
    "        self.recall_af = 0\n",
    "        self.reco_list_af = [] \n",
    "        \n",
    "        # BF\n",
    "        self.grp_factors_bf = []\n",
    "        self.bias_bf = 0\n",
    "        self.precision_bf = 0\n",
    "        self.recall_bf = 0\n",
    "        self.reco_list_bf = []\n",
    "        \n",
    "        # WBF\n",
    "        self.grp_factors_wbf = []\n",
    "        self.bias_wbf = 0\n",
    "        self.precision_wbf = 0\n",
    "        self.recall_wbf = 0\n",
    "        self.weight_matrix_wbf = []\n",
    "        self.reco_list_wbf = []\n",
    "\n",
    "#Configuration reader.\n",
    "class Config:\n",
    "    def __init__(self, config_file_path):\n",
    "        self.config_file_path = config_file_path\n",
    "\n",
    "        configParser = ConfigParser.RawConfigParser()\n",
    "        configParser.read(config_file_path)\n",
    "        \n",
    "        #movie lens 100k dataset, 80 - 20 train/test ratio, present in data directory\n",
    "        self.training_file = configParser.get('Config', 'training_file')\n",
    "        self.testing_file = configParser.get('Config', 'testing_file')\n",
    "        \n",
    "        self.small_grp_size = int(configParser.get('Config', 'small_grp_size'))\n",
    "        self.medium_grp_size = int(configParser.get('Config', 'medium_grp_size'))\n",
    "        self.large_grp_size = int(configParser.get('Config', 'large_grp_size'))\n",
    "        \n",
    "        self.max_iterations_mf = int(configParser.get('Config', 'max_iterations_mf'))\n",
    "        self.lambda_mf = float(configParser.get('Config', 'lambda_mf'))\n",
    "        self.learning_rate_mf = float(configParser.get('Config', 'learning_rate_mf'))\n",
    "        \n",
    "        self.num_factors = int(configParser.get('Config', 'num_factors'))\n",
    "        \n",
    "        #AF (after factorization)\n",
    "        self.rating_threshold_af = float(configParser.get('Config', 'rating_threshold_af'))\n",
    "        self.num_recos_af = int(configParser.get('Config', 'num_recos_af'))\n",
    "        \n",
    "        #BF (before factorization)\n",
    "        self.rating_threshold_bf = float(configParser.get('Config', 'rating_threshold_bf'))\n",
    "        self.num_recos_bf = int(configParser.get('Config', 'num_recos_bf'))\n",
    "        \n",
    "        #WBF (weighted before factorization)\n",
    "        self.rating_threshold_wbf = float(configParser.get('Config', 'rating_threshold_wbf'))\n",
    "        self.num_recos_wbf = int(configParser.get('Config', 'num_recos_wbf'))\n",
    "        \n",
    "        self.is_debug = configParser.getboolean('Config', 'is_debug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating list of movies which can be recommended :</h4>\n",
    "<p>The following function creates a list of movies which have not been watched by any of the members of the group.</p>\n",
    "Our recommendation will be made out of these movies only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def find_candidate_items(ratings, members):\n",
    "    if len(members) == 0: return []\n",
    "\n",
    "    unwatched_items = np.argwhere(ratings[members[0]] == 0)\n",
    "    for member in members:\n",
    "        cur_unwatched = np.argwhere(ratings[member] == 0)\n",
    "        unwatched_items = np.intersect1d(unwatched_items, cur_unwatched)\n",
    "\n",
    "    return unwatched_items\n",
    "Group.find_candidate_items = find_candidate_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def non_testable_items(members, ratings): \n",
    "    non_eval_items = np.argwhere(ratings[members[0]] == 0)\n",
    "    for member in members:\n",
    "        cur_non_eval_items = np.argwhere(ratings[member] == 0)\n",
    "        non_eval_items = np.intersect1d(non_eval_items, cur_non_eval_items)\n",
    "    return non_eval_items\n",
    "Group.non_testable_items = non_testable_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generating groups! </h4>\n",
    "Now we will generate groups from the available users. For better evaluation of our recommendation apporaches, we have to make sure that there are enough items to test upon. So we have set the testable_threshold to be 50, which basically means that there are at least 50 movies in the test data set which have been rated by at least one member of the group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def generate_groups(cfg, ratings, test_ratings, num_users, count, size, disjoint = True):\n",
    "    avbl_users = [i for i in range(num_users)]\n",
    "    groups = []\n",
    "    testable_threshold = 50\n",
    "\n",
    "    iter_idx = 0\n",
    "    while iter_idx in range(count):\n",
    "        group_members = np.random.choice(avbl_users, size = size, replace = False)\n",
    "        candidate_items = Group.find_candidate_items(ratings, group_members)\n",
    "        non_eval_items = Group.non_testable_items(group_members, test_ratings)\n",
    "        testable_items = np.setdiff1d(candidate_items, non_eval_items)\n",
    "\n",
    "        if len(candidate_items) != 0 and len(testable_items) >= testable_threshold:\n",
    "            groups += [Group(group_members, candidate_items, ratings)]\n",
    "            avbl_users = np.setdiff1d(avbl_users, group_members)\n",
    "            iter_idx += 1\n",
    "\n",
    "    return groups\n",
    "    \n",
    "Group.generate_groups = generate_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Prediction!</h4>\n",
    "<p>Now that the groups have been formed, this is the method for finally predicting the movies!</p>\n",
    "We have kept the threshold for predicted rating for an item to be 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_actual_recommendations(self, ratings, threshold):\n",
    "    non_eval_items = Group.non_testable_items(self.members, ratings)\n",
    "\n",
    "    items = np.argwhere(np.logical_or(ratings[self.members[0]] >= threshold, ratings[self.members[0]] == 0)).flatten()\n",
    "    fp = np.argwhere(np.logical_and(ratings[self.members[0]] > 0, ratings[self.members[0]] < threshold)).flatten()\n",
    "    for member in self.members:\n",
    "        cur_items = np.argwhere(np.logical_or(ratings[member] >= threshold, ratings[member] == 0)).flatten()\n",
    "        fp = np.union1d(fp, np.argwhere(np.logical_and(ratings[member] > 0, ratings[member] < threshold)).flatten())\n",
    "        items = np.intersect1d(items, cur_items)\n",
    "\n",
    "    items = np.setdiff1d(items, non_eval_items)\n",
    "\n",
    "    self.actual_recos = items\n",
    "    self.false_positive = fp\n",
    "\n",
    "Group.generate_actual_recommendations  = generate_actual_recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Evaluation :</h4>\n",
    "<p>The following three functions are used for the evaluation of the three methods AF, BF and WBF respectively.</p>\n",
    "We are evaluating the methods using their Precision and Recall for different sizes of groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_af(self, is_debug=False):\n",
    "    tp = float(np.intersect1d(self.actual_recos, self.reco_list_af).size)\n",
    "    fp = float(np.intersect1d(self.false_positive, self.reco_list_af).size)\n",
    "\n",
    "    try:\n",
    "        self.precision_af = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        self.precision_af = np.NaN\n",
    "\n",
    "    try:\n",
    "        self.recall_af = tp / self.actual_recos.size\n",
    "    except ZeroDivisionError:\n",
    "        self.recall_af = np.NaN\n",
    "\n",
    "    if is_debug:\n",
    "        print 'tp: ', tp\n",
    "        print 'fp: ', fp\n",
    "        print 'precision_af: ', self.precision_af\n",
    "        print 'recall_af: ', self.recall_af\n",
    "\n",
    "    return self.precision_af, self.recall_af, tp, fp\n",
    "Group.evaluate_af = evaluate_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_bf(self, is_debug=False):\n",
    "    tp = float(np.intersect1d(self.actual_recos, self.reco_list_bf).size)\n",
    "    fp = float(np.intersect1d(self.false_positive, self.reco_list_bf).size)\n",
    "\n",
    "    try:\n",
    "        self.precision_bf = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        self.precision_bf = np.NaN\n",
    "\n",
    "    try:\n",
    "        self.recall_bf = tp / self.actual_recos.size\n",
    "    except ZeroDivisionError:\n",
    "        self.recall_bf = np.NaN\n",
    "\n",
    "    if is_debug:\n",
    "        print 'tp: ', tp\n",
    "        print 'fp: ', fp\n",
    "        print 'precision_bf: ', self.precision_bf\n",
    "        print 'recall_bf: ', self.recall_bf\n",
    "\n",
    "    return self.precision_bf, self.recall_bf, tp, fp\n",
    "Group.evaluate_bf = evaluate_bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_wbf(self, is_debug=False):\n",
    "    tp = float(np.intersect1d(self.actual_recos, self.reco_list_wbf).size)\n",
    "    fp = float(np.intersect1d(self.false_positive, self.reco_list_wbf).size)\n",
    "\n",
    "    try:\n",
    "        self.precision_wbf = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        self.precision_wbf = np.NaN\n",
    "\n",
    "    try:\n",
    "        self.recall_wbf = tp / self.actual_recos.size\n",
    "    except ZeroDivisionError:\n",
    "        self.recall_wbf = np.NaN\n",
    "\n",
    "    if is_debug:\n",
    "        print 'tp: ', tp\n",
    "        print 'fp: ', fp\n",
    "        print 'precision_bf: ', self.precision_wbf\n",
    "        print 'recall_bf: ', self.recall_wbf\n",
    "\n",
    "    return self.precision_wbf, self.recall_wbf, tp, fp\n",
    "Group.evaluate_wbf = evaluate_wbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Aggregator Class :</h4>\n",
    "This class is responsible for defining different ways to aggregate factors for the member of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "class Aggregators:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #pass ratings or factors as input\n",
    "    @staticmethod\n",
    "    def average(arr):\n",
    "        return np.average(arr, axis = 0, weights = None)\n",
    "\n",
    "    @staticmethod\n",
    "    def average_bf(arr):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            arr[arr == 0] = np.nan\n",
    "            return np.nanmean(arr, axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def weighted_average(arr, weights):\n",
    "        return np.average(arr, axis = 0, weights = weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>GroupRec Class :</h4>\n",
    "This is our main class responsible for reading the data, defining methods for our appoaches and finally evaluating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "\n",
    "\n",
    "# overflow warnings should be raised as errors\n",
    "np.seterr(over='raise')\n",
    "\n",
    "class GroupRec:\n",
    "    def __init__(self):\n",
    "        self.cfg = Config(r\"./config.conf\")\n",
    "        \n",
    "        # training and testing matrices\n",
    "        self.ratings = None\n",
    "        self.test_ratings = None\n",
    "\n",
    "        self.groups = []\n",
    "        \n",
    "        # read data into above matrices\n",
    "        self.read_data()\n",
    "        \n",
    "        self.num_users = self.ratings.shape[0]\n",
    "        self.num_items = self.ratings.shape[1]\n",
    "        \n",
    "        # predicted ratings matrix based on factors.\n",
    "        self.predictions = np.zeros((self.num_users, self.num_items))\n",
    "        \n",
    "        # output after svd factorization\n",
    "        # initialize all unknowns with random values from -1 to 1\n",
    "        self.user_factors = np.random.uniform(-1, 1, (self.ratings.shape[0], self.cfg.num_factors))\n",
    "        self.item_factors = np.random.uniform(-1, 1, (self.ratings.shape[1], self.cfg.num_factors))\n",
    "\n",
    "        self.user_biases = np.zeros(self.num_users)\n",
    "        self.item_biases = np.zeros(self.num_items)\n",
    "        \n",
    "        # global mean of ratings a.k.a mu\n",
    "        self.ratings_global_mean = 0\n",
    "\n",
    "    # add list of groups\n",
    "    def add_groups(self, groups):\n",
    "        self.groups = groups\n",
    "    \n",
    "    # remove groups\n",
    "    def remove_groups(self, groups):\n",
    "        self.groups = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reading the data : </h4>\n",
    "We have used 'pandas' library for reading testing data and training data from the csv file.\n",
    "We will finally generate our user * item ratings matrix here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read training and testing data into matrices\n",
    "def read_data(self):\n",
    "    column_headers = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "    print 'Reading training data from ', self.cfg.training_file, '...'\n",
    "    training_data = ps.read_csv(self.cfg.training_file, sep='\\t', names=column_headers)\n",
    "\n",
    "    print 'Reading testing data from ', self.cfg.testing_file, '...'\n",
    "    testing_data = ps.read_csv(self.cfg.testing_file, sep='\\t', names=column_headers)\n",
    "\n",
    "    num_users = max(training_data.user_id.unique())\n",
    "    num_items = max(training_data.item_id.unique())\n",
    "\n",
    "    self.ratings = np.zeros((num_users, num_items))\n",
    "    self.test_ratings = np.zeros((num_users, num_items))\n",
    "\n",
    "    for row in training_data.itertuples(index=False):\n",
    "        self.ratings[row.user_id - 1, row.item_id - 1] = row.rating\n",
    "\n",
    "    for row in testing_data.itertuples(index=False):\n",
    "        self.test_ratings[row.user_id - 1, row.item_id - 1] = row.rating\n",
    "        \n",
    "GroupRec.read_data = read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Matrix Factorization : </h4>\n",
    "Now we would like to factorize the rating matrix. \n",
    "We have considered the number of factors to be 15.\n",
    "And we are using gradient descent for error minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_factorize(self):\n",
    "    #solve for these for matrix ratings        \n",
    "    ratings_row, ratings_col = self.ratings.nonzero()\n",
    "    num_ratings = len(ratings_row)\n",
    "    learning_rate = self.cfg.learning_rate_mf\n",
    "    regularization = self.cfg.lambda_mf\n",
    "\n",
    "    self.ratings_global_mean = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "\n",
    "    print 'Doing matrix factorization...'\n",
    "    try:\n",
    "        for iter in range(self.cfg.max_iterations_mf):\n",
    "            print 'Iteration: ', iter\n",
    "            rating_indices = np.arange(num_ratings)\n",
    "            np.random.shuffle(rating_indices)\n",
    "\n",
    "            for idx in rating_indices:\n",
    "                user = ratings_row[idx]\n",
    "                item = ratings_col[idx]\n",
    "\n",
    "                pred = self.predict_user_rating(user, item)\n",
    "                error = self.ratings[user][item] - pred\n",
    "\n",
    "                self.user_factors[user] += learning_rate \\\n",
    "                                            * ((error * self.item_factors[item]) - (regularization * self.user_factors[user]))\n",
    "                self.item_factors[item] += learning_rate \\\n",
    "                                            * ((error * self.user_factors[user]) - (regularization * self.item_factors[item]))\n",
    "\n",
    "                self.user_biases[user] += learning_rate * (error - regularization * self.user_biases[user])\n",
    "                self.item_biases[item] += learning_rate * (error - regularization * self.item_biases[item])\n",
    "\n",
    "            self.sgd_mse()\n",
    "\n",
    "    except FloatingPointError:\n",
    "        print 'Floating point Error: '\n",
    "GroupRec.sgd_factorize = sgd_factorize\n",
    "\n",
    "\n",
    "def sgd_mse(self):\n",
    "    self.predict_all_ratings()\n",
    "    predicted_training_ratings = self.predictions[self.ratings.nonzero()].flatten()\n",
    "    actual_training_ratings = self.ratings[self.ratings.nonzero()].flatten()\n",
    "\n",
    "    predicted_test_ratings = self.predictions[self.test_ratings.nonzero()].flatten()\n",
    "    actual_test_ratings = self.test_ratings[self.test_ratings.nonzero()].flatten()\n",
    "\n",
    "    training_mse = mean_squared_error(predicted_training_ratings, actual_training_ratings)\n",
    "    print 'training mse: ', training_mse\n",
    "    test_mse = mean_squared_error(predicted_test_ratings, actual_test_ratings)\n",
    "    print 'test mse: ', test_mse\n",
    "GroupRec.sgd_mse = sgd_mse\n",
    "\n",
    "\n",
    "def predict_user_rating(self, user, item):\n",
    "    prediction = self.ratings_global_mean + self.user_biases[user] + self.item_biases[item]\n",
    "    prediction += self.user_factors[user, :].dot(self.item_factors[item, :].T)\n",
    "    return prediction\n",
    "GroupRec.predict_user_rating = predict_user_rating\n",
    "\n",
    "def predict_group_rating(self, group, item, method):\n",
    "    if (method == 'af'):\n",
    "        factors = group.grp_factors_af; bias_group = group.bias_af\n",
    "    elif (method == 'bf'):\n",
    "        factors = group.grp_factors_bf; bias_group = group.bias_bf\n",
    "    elif (method == 'wbf'):\n",
    "        factors = group.grp_factors_wbf; bias_group = group.bias_wbf\n",
    "\n",
    "    return self.ratings_global_mean + bias_group + self.item_biases[item] \\\n",
    "                                    + np.dot(factors.T, self.item_factors[item])\n",
    "GroupRec.predict_group_rating = predict_group_rating\n",
    "\n",
    "def predict_all_ratings(self):\n",
    "    for user in range(self.num_users):\n",
    "        for item in range(self.num_items):\n",
    "            self.predictions[user, item] = self.predict_user_rating(user, item)\n",
    "GroupRec.predict_all_ratings = predict_all_ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>After Factorization (AF) Method Definition.....</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AF method\n",
    "def af_runner(self, groups = None, aggregator = Aggregators.average):\n",
    "    #if groups is not passed, use self.groups\n",
    "    if (groups is None):\n",
    "        groups = self.groups\n",
    "\n",
    "    #calculate factors\n",
    "    for group in groups:\n",
    "        member_factors = self.user_factors[group.members, :]\n",
    "        member_biases = self.user_biases[group.members]\n",
    "\n",
    "        #aggregate the factors\n",
    "        if (aggregator == Aggregators.average):\n",
    "            group.grp_factors_af = aggregator(member_factors)\n",
    "            group.bias_af = aggregator(member_biases)\n",
    "        elif (aggregator == Aggregators.weighted_average):\n",
    "            group.grp_factors_af = aggregator(member_factors, weights = group.ratings_per_member)\n",
    "            group.bias_af = aggregator(member_biases, weights = group.ratings_per_member)\n",
    "\n",
    "        #predict ratings for all candidate items\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(group.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(group, item, 'af')\n",
    "\n",
    "            if (cur_rating > self.cfg.rating_threshold_af):\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        #sort and filter to keep top 'num_recos_af' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[:self.cfg.num_recos_af]\n",
    "\n",
    "        group.reco_list_af = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "GroupRec.af_runner = af_runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Before Factorization(BF) Method.....</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def bf_runner(self, groups=None, aggregator=Aggregators.average_bf):\n",
    "    # aggregate user ratings into virtual group\n",
    "    # calculate factors of group\n",
    "    lamb = self.cfg.lambda_mf\n",
    "\n",
    "    for group in groups:\n",
    "        all_movies = np.arange(len(self.ratings.T))\n",
    "        watched_items = sorted(list(set(all_movies) - set(group.candidate_items)))\n",
    "\n",
    "        group_rating = self.ratings[group.members, :]\n",
    "        agg_rating = aggregator(group_rating)\n",
    "        s_g = []\n",
    "        for j in watched_items:\n",
    "            s_g.append(agg_rating[j] - self.ratings_global_mean - self.item_biases[j])\n",
    "\n",
    "        # creating matrix A : contains rows of [item_factors of items in watched_list + '1' vector]\n",
    "        A = np.zeros((0, self.cfg.num_factors))\n",
    "\n",
    "        for item in watched_items:\n",
    "            A = np.vstack([A, self.item_factors[item]])\n",
    "        v = np.ones((len(watched_items), 1))\n",
    "        A = np.c_[A, v]\n",
    "\n",
    "        factor_n_bias = np.dot(np.linalg.inv(np.dot(A.T, A) + lamb * np.identity(self.cfg.num_factors + 1)), np.dot(A.T, s_g))\n",
    "        group.grp_factors_bf = factor_n_bias[:-1]\n",
    "        group.bias_bf = factor_n_bias[-1]\n",
    "\n",
    "        # Making recommendations on candidate list :\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(group.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(group, item, 'bf')\n",
    "\n",
    "            if (cur_rating > self.cfg.rating_threshold_bf):\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        # sort and filter to keep top 'num_recos_bf' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[\n",
    "                                  :self.cfg.num_recos_bf]\n",
    "\n",
    "        group.reco_list_bf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "        \n",
    "GroupRec.bf_runner = bf_runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Weighted Before Factorization Method (WBF).....</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wbf_runner(self, groups=None, aggregator=Aggregators.average_bf):\n",
    "    # aggregate user ratings into virtual group\n",
    "    # calculate factors of group\n",
    "    lamb = self.cfg.lambda_mf\n",
    "    for group in groups:\n",
    "        all_movies = np.arange(len(self.ratings.T))\n",
    "        watched_items = sorted(list(set(all_movies) - set(group.candidate_items)))\n",
    "\n",
    "        group_rating = self.ratings[group.members, :]\n",
    "        agg_rating = aggregator(group_rating)\n",
    "        s_g = []\n",
    "        for j in watched_items:\n",
    "            s_g.append(agg_rating[j] - self.ratings_global_mean - self.item_biases[j])\n",
    "\n",
    "        # creating matrix A : contains rows of [item_factors of items in watched_list + '1' vector]\n",
    "        A = np.zeros((0, self.cfg.num_factors))  # 3 is the number of features here = K\n",
    "\n",
    "        for item in watched_items:\n",
    "            A = np.vstack([A, self.item_factors[item]])\n",
    "        v = np.ones((len(watched_items), 1))\n",
    "        A = np.c_[A, v]\n",
    "\n",
    "        wt = []\n",
    "        for item in watched_items:\n",
    "            rated = np.argwhere(self.ratings[:, item] != 0)  # list of users who have rated this movie\n",
    "            watched = np.intersect1d(rated, group)  # list of group members who have watched this movie\n",
    "            std_dev = np.std(filter(lambda a: a != 0, self.ratings[:, item]))  # std deviation for the rating of the item\n",
    "            wt += [len(watched) / float(len(group.members)) * 1 / (1 + std_dev)]  # list containing diagonal elements\n",
    "        W = np.diag(wt)  # diagonal weight matrix\n",
    "\n",
    "        factor_n_bias = np.dot(np.linalg.inv(np.dot(np.dot(A.T, W),A) + lamb * np.identity(self.cfg.num_factors + 1)),\n",
    "                               np.dot(np.dot(A.T, W), s_g))\n",
    "        group.grp_factors_wbf = factor_n_bias[:-1]\n",
    "        group.bias_wbf = factor_n_bias[-1]\n",
    "\n",
    "        # Making recommendations on candidate list :\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(group.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(group, item, 'wbf')\n",
    "\n",
    "            if (cur_rating > self.cfg.rating_threshold_wbf):\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        # sort and filter to keep top 'num_recos_wbf' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[\n",
    "                                  :self.cfg.num_recos_wbf]\n",
    "\n",
    "        group.reco_list_wbf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "GroupRec.wbf_runner = wbf_runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Evaluating our methods......</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(self):\n",
    "    # For AF\n",
    "    af_precision_list = []\n",
    "    af_recall_list = []\n",
    "    print \"\\n#########-------For AF-------#########\"\n",
    "    for grp in self.groups:\n",
    "        grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_af)\n",
    "        (precision, recall, tp, fp) = grp.evaluate_af()\n",
    "        af_precision_list.append(precision)\n",
    "        af_recall_list.append(recall)\n",
    "\n",
    "    af_mean_precision = np.nanmean(np.array(af_precision_list))\n",
    "    af_mean_recall = np.nanmean(np.array(af_recall_list))\n",
    "    print '\\nAF method: mean precision: ', af_mean_precision\n",
    "    print 'AF method: mean recall: ', af_mean_recall\n",
    "\n",
    "    # For BF\n",
    "    bf_precision_list = []\n",
    "    bf_recall_list = []\n",
    "    print \"\\n#########-------For BF-------#########\"\n",
    "    for grp in self.groups:\n",
    "        grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_bf)\n",
    "        (precision, recall, tp, fp) = grp.evaluate_bf()\n",
    "        bf_precision_list.append(precision)\n",
    "        bf_recall_list.append(recall)\n",
    "\n",
    "    bf_mean_precision = np.nanmean(np.array(bf_precision_list))\n",
    "    bf_mean_recall = np.nanmean(np.array(bf_recall_list))\n",
    "    print '\\nBF method: mean precision: ', bf_mean_precision\n",
    "    print 'BF method: mean recall: ', bf_mean_recall\n",
    "\n",
    "    # For WBF\n",
    "    wbf_precision_list = []\n",
    "    wbf_recall_list = []\n",
    "    print \"\\n#########-------For WBF-------#########\"\n",
    "    for grp in self.groups:\n",
    "        grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_wbf)\n",
    "        (precision, recall, tp, fp) = grp.evaluate_wbf()\n",
    "        wbf_precision_list.append(precision)\n",
    "        wbf_recall_list.append(recall)\n",
    "\n",
    "    wbf_mean_precision = np.nanmean(np.array(wbf_precision_list))\n",
    "    wbf_mean_recall = np.nanmean(np.array(wbf_recall_list))\n",
    "    print '\\nWBF method: mean precision: ', wbf_mean_precision\n",
    "    print 'WBF method: mean recall: ', wbf_mean_recall\n",
    "GroupRec.evaluation = evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are running all our proposed methods and evaluating them altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_all_methods(self, groups):\n",
    "    if (groups is None):\n",
    "        groups = self.groups\n",
    "    #PS: could call them without passing groups as we have already added groups to grouprec object\n",
    "    self.af_runner(groups, Aggregators.weighted_average)\n",
    "    self.bf_runner(groups, Aggregators.average_bf)\n",
    "    self.wbf_runner(groups, Aggregators.average_bf)\n",
    "\n",
    "    #evaluation\n",
    "    self.evaluation()\n",
    "GroupRec.run_all_methods = run_all_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Our class definitions end here***\n",
    "Starting from here, this can be treated as the main script for the entire code.\n",
    "\n",
    "First, Here we complete the matrix factorization with SGD method. The number of iterations is taken from the\n",
    "config file and MSE over the iterations is reported. We are only doing 3 iterations in this demo so the mse(error) is higher.\n",
    "For our results, we have done more iterations to get lesser mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data from  ./data/u1.base ...\n",
      "Reading testing data from  ./data/u1.test ...\n",
      "3\n",
      "Doing matrix factorization...\n",
      "Iteration:  0\n",
      "training mse:  0.804040513916\n",
      "test mse:  1.06135925559\n",
      "Iteration:  1\n",
      "training mse:  0.751241470881\n",
      "test mse:  1.00285680951\n",
      "Iteration:  2\n",
      "training mse:  0.716987513441\n",
      "test mse:  0.982651195692\n"
     ]
    }
   ],
   "source": [
    "gr = GroupRec()\n",
    "print(gr.cfg.max_iterations_mf)\n",
    "gr.sgd_factorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate small, medium and large groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Running for  small  groups *************\n",
      "generated groups (only first 5 are getting printed here): \n",
      "[138, 143, 170]\n",
      "[13, 157, 731]\n",
      "[76, 269, 492]\n",
      "[168, 289, 348]\n",
      "[6, 130, 407]\n",
      "\n",
      "******* Running for  medium  groups *************\n",
      "generated groups (only first 5 are getting printed here): \n",
      "[29, 52, 89, 637, 684]\n",
      "[187, 292, 792, 911, 939]\n",
      "[17, 64, 524, 555, 617]\n",
      "[118, 398, 790, 880, 908]\n",
      "[228, 302, 328, 620, 632]\n",
      "\n",
      "******* Running for  large  groups *************\n",
      "generated groups (only first 5 are getting printed here): \n",
      "[28, 180, 200, 256, 288, 558, 629, 652, 657, 906]\n",
      "[48, 49, 206, 439, 566, 586, 604, 721, 732, 871]\n",
      "[14, 135, 248, 294, 495, 516, 540, 618, 632, 867]\n",
      "[67, 129, 161, 380, 412, 420, 785, 806, 848, 876]\n",
      "[11, 81, 154, 186, 225, 396, 422, 589, 810, 937]\n"
     ]
    }
   ],
   "source": [
    "#generate groups programmatically\n",
    "#disjoint means none of the groups shares any common members     \n",
    "small_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 10, gr.cfg.small_grp_size, disjoint=True)\n",
    "medium_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 10, gr.cfg.medium_grp_size, disjoint=True)\n",
    "large_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 10, gr.cfg.large_grp_size, disjoint=True)\n",
    "\n",
    "group_set = [small_groups, medium_groups, large_groups]\n",
    "group_type = ['small', 'medium', 'large']\n",
    "\n",
    "for idx, groups in enumerate(group_set):\n",
    "    if groups is []:\n",
    "        continue\n",
    "\n",
    "    # generated groups\n",
    "    n = 5\n",
    "    print '\\n******* Running for ', group_type[idx], ' groups *************'\n",
    "    print 'generated groups (only first %d are getting printed here): ' % n\n",
    "    for group in groups[:n]:\n",
    "        print(group.members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run all the methods (AF, BF and WBF) for all the 3 group sizes and report the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Running for  small  groups *************\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.891975308642\n",
      "AF method: mean recall:  0.078553826024\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.933723196881\n",
      "BF method: mean recall:  0.0254755079576\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.978571428571\n",
      "WBF method: mean recall:  0.132310142385\n",
      "\n",
      "******* Running for  medium  groups *************\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.781984126984\n",
      "AF method: mean recall:  0.065607168512\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  1.0\n",
      "BF method: mean recall:  0.0242281437278\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.957863247863\n",
      "WBF method: mean recall:  0.0950595452294\n",
      "\n",
      "******* Running for  large  groups *************\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.693560606061\n",
      "AF method: mean recall:  0.0403437788258\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.805555555556\n",
      "BF method: mean recall:  0.0187107824332\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.94788961039\n",
      "WBF method: mean recall:  0.050668678502\n"
     ]
    }
   ],
   "source": [
    "for idx, groups in enumerate(group_set):\n",
    "    if groups is []:\n",
    "        continue\n",
    "    print '\\n******* Running for ', group_type[idx], ' groups *************'\n",
    "\n",
    "    gr.add_groups(groups)\n",
    "    gr.run_all_methods(groups)\n",
    "    gr.remove_groups(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Methodology:\n",
    "\n",
    "We follow similar evaluation methods as the paper.\n",
    "\n",
    "These are the evaluation metrics\n",
    "\n",
    "![title](./res/evaluation_metrics.png)\n",
    "\n",
    "To put it simply, __we count a movie recommendation as positive, if the test ratings for all the users in that group exceeds the user satisfaction threshold : rating of 4__ and there should be atleast 1 user in group with given test rating. (Note that test dataset is very sparse)\n",
    "\n",
    "For evaluation, we run all the 3 methods: AF, BF and WBF for 50 randomly generated groups from among the users in the Movielens\n",
    "dataset.\n",
    "These groups are non disjoint in the sense that same user can be present in multiple groups.\n",
    "\n",
    "Here are the configuration parameters stated again all at once:\n",
    "\n",
    "__Matrix Factorization hyperparameters__:\n",
    "<li> No. of factors = 15 </li>\n",
    "<li> lambda(regularization) = 0.1 </li>\n",
    "<li> neta (learning rate) = 0.07 </li>\n",
    "\n",
    "__User Satisfaction Threshold__:\n",
    "<li> 4 </li>\n",
    "\n",
    "__Group Parameters__:\n",
    "<li> small group = 3 users </li>\n",
    "<li> medium group = 5 users </li>\n",
    "<li> large group = 8 users </li>\n",
    "<li> No. of Recommendations per user = 50 </li>\n",
    "\n",
    "\n",
    "### Results:\n",
    "\n",
    "#### Precision and Recall for all groups:\n",
    "\n",
    "![title](./res/result.png)\n",
    "    \n",
    "We note that the AF method works best for small groups followed by Weighted before method. \n",
    "For the medium groups as well, this is the case but the margin of difference is lower between the small and medium groups.\n",
    "\n",
    "For larger groups, the WBF method outperforms the AF method and reports better accuracy. Increasing the group size further to very large ( > 15) should further increase the success margin of WBF.\n",
    "\n",
    "We note that BF method (no weights) performs worse than both AF and WBF for all the 3 group sizes.\n",
    "\n",
    "We note that the recall for methods is pretty low. The low recall values are in keeping with the data reported by the paper.\n",
    "\n",
    "###### Reason for low recall:\n",
    "Note that we only report top 50 recommendation per group.\n",
    "\n",
    "Also, since the test data is very sparse, there are lot of movies in our recommendations for which there is no rating data for\n",
    "any member of the group in the test set. Hence, we cannot calculate the precision / recall for these movies as we dont know\n",
    "whether to interpret them as positive or negative matches.\n",
    "\n",
    "In short, our total set of True positives is not known due to sparse data.\n",
    "\n",
    "### Final Comments:\n",
    "Our reported precision metrics match with those reported in the paper. One difference is that author reports far better results for BF and WBF with small and large groups.\n",
    "\n",
    "This could be attributable to the fact that datasets are different. Author uses Movielens-1MB dataset while we are using 100K\n",
    "dataset.\n",
    "\n",
    "Author mentions that when the data is sparse, AF performs quite well which is the case in our Movielens 100 K dataset.\n",
    "\n",
    "Once the data is increased, more data is involved in group recommendation process and AF approach does not work properly. A virtual user is better representation for the group of users than the aggregation of users' factors in this case. \n",
    "Both BF and WBF make better recommendations for non-sparse datasets.\n",
    "\n",
    "Similar effect is at work when no. of users per group is increased.(more data is involved) In this case too, AF method performs worse gradually than WBF.\n",
    "\n",
    "__Note__: These reported results have been generated over very large number of iterations. However, the working version of this notebook has very less number of matrix factorization iterations and number of groups to make the time taken for running the code manageable. Hence, the mean precision and recall output by running this notebook may not align exactly with the reported results. Moreover there is random initialization of the factors in matrix factorization which leads to slightly different results different times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Future Work:\n",
    "\n",
    "(i) \n",
    "(a) This was an exciting project and we had a lot of practical learning. We got to know about different Python libraries for data processing (Pandas) and matrix processing. \n",
    "\n",
    "(b) We got an insight into the hyperparameter tuning process and overfitting. Initially, we kept learning rate very high and saw that the mean squared error (MSE) for training data decreased to very low but the MSE for test data kept on increasing. We\n",
    "decreased learning rate and carefully checked for overfitting in the iterations for matrix factorization.\n",
    "\n",
    "(ii) \n",
    "(a)  We applied matrix factorization technique learned in the course and tried it for a different domain i.e. group recommendations.\n",
    "Since 'group recommendation' is a relatively less explored field (we found very less research papers on it), there is a lot of\n",
    "scope for improvement in the techniques.\n",
    "\n",
    "(b) Moreover, although we have applied it to movie dataset, the technique of aggregating individual user ratings to evaluate group satisfaction is fairly general and can be applied to other domains, for eg. travel destination suggestions\n",
    "\n",
    "(d) We learned that real data is sparse and the traditional metrics. i.e. recall and precision can't be evaluated in all the cases. In these cases, some redefinition of metrics is required for domain.\n",
    "\n",
    "\n",
    "(iii) \n",
    "(a) We see that the precision of all the methods is heavily dependent on the initial matrix factorization step. The method of embeddings that we learnt in the class can be used for more accurate matrix factorization. Specifically we can\n",
    "use deep learning based neural networks (CNN) for more accurate matrix factorization. The mean squared error achieved with neural networks is less than normal SGD methods.\n",
    "Given link shows good illustration of this:\n",
    "https://github.com/bradleypallen/keras-movielens-cf/blob/master/MovieLens%201M%20Recommendations.ipynb\n",
    "\n",
    "In Future, we would like to improve on the following:\n",
    "##### Dataset:\n",
    "We used the movie lens 100K database for this project. We tried for larger Movielens complete dataset of 100 MB entries but\n",
    "could not process this much data due to computational limitations. Matrix Factorization takes a lot of time as the no. of\n",
    "entries increase. Netflix dataset was even larger.\n",
    "\n",
    "##### Better Data Structures:\n",
    "We could try the Sparse Matrix Data Structures given in SciPy in future and store results of different parts of computation\n",
    "as files on disk so that we do matrix factorization only once and reuse the user and item factors over and over.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. MovieLens Dataset- https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "2. Ortega, Fernando, et al. \"Recommending items to group of users using Matrix Factorization based Collaborative Filtering.\"\n",
    "Information Sciences 345 (2016): 313-324\n",
    "http://www.sciencedirect.com/science/article/pii/S0020025516300196"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
